{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b33e4dd-49c1-45c3-be95-2e762ff3ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import deque\n",
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "\n",
    "dis = 0.9\n",
    "REPLAY_MEMORY = 50000\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(self.input_size,)),\n",
    "            tf.keras.layers.Dense(24, activation='relu'),\n",
    "            tf.keras.layers.Dense(24, activation='relu'),\n",
    "            tf.keras.layers.Dense(self.output_size)\n",
    "        ])\n",
    "        model.compile(optimizer=self.optimizer, loss='mse')\n",
    "        return model\n",
    "\n",
    "    def predict(self, state):\n",
    "        state = np.reshape(state, [-1, self.input_size])\n",
    "        return self.model(state)\n",
    "\n",
    "    @tf.function\n",
    "    def update(self, x_stack, y_stack):\n",
    "        with tf.GradientTape() as tape:\n",
    "            q_values = self.model(x_stack)\n",
    "            loss = tf.reduce_mean(tf.square(y_stack - q_values))\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "def simple_replay_train(DQN, train_batch):\n",
    "    x_stack = np.empty(0).reshape(0, DQN.input_size)\n",
    "    y_stack = np.empty(0).reshape(0, DQN.output_size)\n",
    "\n",
    "    for state, action, reward, next_state, done in train_batch:\n",
    "        Q = DQN.predict(state).numpy()\n",
    "\n",
    "        if done:\n",
    "            Q[0, action] = reward\n",
    "        else:\n",
    "            Q[0, action] = reward + dis * np.max(DQN.predict(next_state))\n",
    "\n",
    "        y_stack = np.vstack([y_stack, Q])\n",
    "        x_stack = np.vstack([x_stack, state])\n",
    "\n",
    "    y_stack = y_stack.astype(np.float32)\n",
    "\n",
    "    return DQN.update(x_stack, y_stack)\n",
    "\n",
    "def bot_play(mainDQN):\n",
    "    s = env.reset()[0]\n",
    "    reward_sum = 0\n",
    "\n",
    "    while True:\n",
    "        env.render()\n",
    "        a = np.argmax(mainDQN.predict(s))\n",
    "        s, reward, done, _, _ = env.step(a)\n",
    "        reward_sum += reward\n",
    "\n",
    "        if done:\n",
    "            print(\"Total score: {}\".format(reward_sum))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edccb2a-7e59-4d2d-a0ee-7830b664b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    max_episodes = 5000\n",
    "    replay_buffer = deque(maxlen=REPLAY_MEMORY)\n",
    "\n",
    "    mainDQN = DQN(input_size, output_size)\n",
    "\n",
    "    for episode in range(max_episodes):\n",
    "        e = 1. / ((episode / 10) + 1)\n",
    "        done = False\n",
    "        step_count = 0\n",
    "\n",
    "        state = env.reset()[0]\n",
    "\n",
    "        while not done:\n",
    "            if np.random.rand(1) < e:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(mainDQN.predict(state))\n",
    "\n",
    "            next_state, reward, done, _, _ = env.step(action)\n",
    "\n",
    "            if done:\n",
    "                reward = -100\n",
    "\n",
    "            replay_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "            state = next_state\n",
    "            step_count += 1\n",
    "            if step_count > 10000:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode: {episode} steps: {step_count}\")\n",
    "\n",
    "        if episode % 10 == 1 and len(replay_buffer) >= 10:\n",
    "            for _ in range(50):\n",
    "                minibatch = random.sample(replay_buffer, 10)\n",
    "                loss = simple_replay_train(mainDQN, minibatch)\n",
    "            print(\"Loss: \", loss.numpy())\n",
    "\n",
    "        if episode % 50 == 0:\n",
    "            bot_play(mainDQN)\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba857f43-4c20-4c2c-8db0-21ed8b121d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/gym/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/opt/anaconda3/envs/gym/lib/python3.12/site-packages/gym/envs/classic_control/cartpole.py:211: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym(\"CartPole-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 steps: 30\n",
      "Total score: 9.0\n",
      "Episode: 1 steps: 10\n",
      "Loss:  491.50177\n",
      "Episode: 2 steps: 24\n",
      "Episode: 3 steps: 27\n",
      "Episode: 4 steps: 18\n",
      "Episode: 5 steps: 11\n",
      "Episode: 6 steps: 14\n",
      "Episode: 7 steps: 19\n",
      "Episode: 8 steps: 10\n",
      "Episode: 9 steps: 13\n",
      "Episode: 10 steps: 28\n",
      "Episode: 11 steps: 10\n",
      "Loss:  0.5737263\n",
      "Episode: 12 steps: 13\n",
      "Episode: 13 steps: 14\n",
      "Episode: 14 steps: 13\n",
      "Episode: 15 steps: 12\n",
      "Episode: 16 steps: 9\n",
      "Episode: 17 steps: 11\n",
      "Episode: 18 steps: 15\n",
      "Episode: 19 steps: 13\n",
      "Episode: 20 steps: 12\n",
      "Episode: 21 steps: 10\n",
      "Loss:  942.6343\n",
      "Episode: 22 steps: 10\n",
      "Episode: 23 steps: 12\n",
      "Episode: 24 steps: 14\n",
      "Episode: 25 steps: 9\n",
      "Episode: 26 steps: 12\n",
      "Episode: 27 steps: 12\n",
      "Episode: 28 steps: 11\n",
      "Episode: 29 steps: 10\n",
      "Episode: 30 steps: 14\n",
      "Episode: 31 steps: 11\n",
      "Loss:  1.4555897\n",
      "Episode: 32 steps: 13\n",
      "Episode: 33 steps: 12\n",
      "Episode: 34 steps: 10\n",
      "Episode: 35 steps: 10\n",
      "Episode: 36 steps: 14\n",
      "Episode: 37 steps: 10\n",
      "Episode: 38 steps: 10\n",
      "Episode: 39 steps: 9\n",
      "Episode: 40 steps: 10\n",
      "Episode: 41 steps: 10\n",
      "Loss:  0.36468476\n",
      "Episode: 42 steps: 10\n",
      "Episode: 43 steps: 9\n",
      "Episode: 44 steps: 9\n",
      "Episode: 45 steps: 10\n",
      "Episode: 46 steps: 10\n",
      "Episode: 47 steps: 10\n",
      "Episode: 48 steps: 9\n",
      "Episode: 49 steps: 11\n",
      "Episode: 50 steps: 15\n",
      "Total score: 10.0\n",
      "Episode: 51 steps: 10\n",
      "Loss:  851.07245\n",
      "Episode: 52 steps: 50\n",
      "Episode: 53 steps: 44\n",
      "Episode: 54 steps: 38\n",
      "Episode: 55 steps: 28\n",
      "Episode: 56 steps: 23\n",
      "Episode: 57 steps: 46\n",
      "Episode: 58 steps: 44\n",
      "Episode: 59 steps: 70\n",
      "Episode: 60 steps: 41\n",
      "Episode: 61 steps: 34\n",
      "Loss:  0.7408551\n",
      "Episode: 62 steps: 10\n",
      "Episode: 63 steps: 9\n",
      "Episode: 64 steps: 10\n",
      "Episode: 65 steps: 9\n",
      "Episode: 66 steps: 9\n",
      "Episode: 67 steps: 8\n",
      "Episode: 68 steps: 9\n",
      "Episode: 69 steps: 10\n",
      "Episode: 70 steps: 12\n",
      "Episode: 71 steps: 10\n",
      "Loss:  0.8307101\n",
      "Episode: 72 steps: 10\n",
      "Episode: 73 steps: 9\n",
      "Episode: 74 steps: 9\n",
      "Episode: 75 steps: 9\n",
      "Episode: 76 steps: 10\n",
      "Episode: 77 steps: 13\n",
      "Episode: 78 steps: 9\n",
      "Episode: 79 steps: 10\n",
      "Episode: 80 steps: 10\n",
      "Episode: 81 steps: 11\n",
      "Loss:  518.60046\n",
      "Episode: 82 steps: 25\n",
      "Episode: 83 steps: 28\n",
      "Episode: 84 steps: 33\n",
      "Episode: 85 steps: 35\n",
      "Episode: 86 steps: 31\n",
      "Episode: 87 steps: 23\n",
      "Episode: 88 steps: 21\n",
      "Episode: 89 steps: 27\n",
      "Episode: 90 steps: 21\n",
      "Episode: 91 steps: 30\n",
      "Loss:  306.18243\n",
      "Episode: 92 steps: 67\n",
      "Episode: 93 steps: 36\n",
      "Episode: 94 steps: 134\n",
      "Episode: 95 steps: 46\n",
      "Episode: 96 steps: 53\n",
      "Episode: 97 steps: 29\n",
      "Episode: 98 steps: 36\n",
      "Episode: 99 steps: 26\n",
      "Episode: 100 steps: 27\n",
      "Total score: 61.0\n",
      "Episode: 101 steps: 66\n",
      "Loss:  491.8016\n",
      "Episode: 102 steps: 29\n",
      "Episode: 103 steps: 31\n",
      "Episode: 104 steps: 32\n",
      "Episode: 105 steps: 27\n",
      "Episode: 106 steps: 24\n",
      "Episode: 107 steps: 31\n",
      "Episode: 108 steps: 44\n",
      "Episode: 109 steps: 25\n",
      "Episode: 110 steps: 78\n",
      "Episode: 111 steps: 45\n",
      "Loss:  5.986329\n",
      "Episode: 112 steps: 33\n",
      "Episode: 113 steps: 33\n",
      "Episode: 114 steps: 31\n",
      "Episode: 115 steps: 36\n",
      "Episode: 116 steps: 28\n",
      "Episode: 117 steps: 35\n",
      "Episode: 118 steps: 32\n",
      "Episode: 119 steps: 38\n",
      "Episode: 120 steps: 38\n",
      "Episode: 121 steps: 41\n",
      "Loss:  494.85513\n",
      "Episode: 122 steps: 26\n",
      "Episode: 123 steps: 29\n",
      "Episode: 124 steps: 22\n",
      "Episode: 125 steps: 35\n",
      "Episode: 126 steps: 34\n",
      "Episode: 127 steps: 26\n",
      "Episode: 128 steps: 32\n",
      "Episode: 129 steps: 30\n",
      "Episode: 130 steps: 36\n",
      "Episode: 131 steps: 30\n",
      "Loss:  3.8926272\n",
      "Episode: 132 steps: 21\n",
      "Episode: 133 steps: 32\n",
      "Episode: 134 steps: 29\n",
      "Episode: 135 steps: 34\n",
      "Episode: 136 steps: 36\n",
      "Episode: 137 steps: 26\n",
      "Episode: 138 steps: 48\n",
      "Episode: 139 steps: 25\n",
      "Episode: 140 steps: 37\n",
      "Episode: 141 steps: 43\n",
      "Loss:  452.2307\n",
      "Episode: 142 steps: 57\n",
      "Episode: 143 steps: 48\n",
      "Episode: 144 steps: 38\n",
      "Episode: 145 steps: 40\n",
      "Episode: 146 steps: 29\n",
      "Episode: 147 steps: 41\n",
      "Episode: 148 steps: 40\n",
      "Episode: 149 steps: 25\n",
      "Episode: 150 steps: 32\n",
      "Total score: 38.0\n",
      "Episode: 151 steps: 52\n",
      "Loss:  483.6857\n",
      "Episode: 152 steps: 32\n",
      "Episode: 153 steps: 36\n",
      "Episode: 154 steps: 30\n",
      "Episode: 155 steps: 28\n",
      "Episode: 156 steps: 43\n",
      "Episode: 157 steps: 31\n",
      "Episode: 158 steps: 57\n",
      "Episode: 159 steps: 51\n",
      "Episode: 160 steps: 28\n",
      "Episode: 161 steps: 46\n",
      "Loss:  1.3678675\n",
      "Episode: 162 steps: 35\n",
      "Episode: 163 steps: 36\n",
      "Episode: 164 steps: 34\n",
      "Episode: 165 steps: 26\n",
      "Episode: 166 steps: 56\n",
      "Episode: 167 steps: 124\n",
      "Episode: 168 steps: 33\n",
      "Episode: 169 steps: 54\n",
      "Episode: 170 steps: 26\n",
      "Episode: 171 steps: 35\n",
      "Loss:  2.3030791\n",
      "Episode: 172 steps: 68\n",
      "Episode: 173 steps: 32\n",
      "Episode: 174 steps: 44\n",
      "Episode: 175 steps: 32\n",
      "Episode: 176 steps: 34\n",
      "Episode: 177 steps: 69\n",
      "Episode: 178 steps: 51\n",
      "Episode: 179 steps: 32\n",
      "Episode: 180 steps: 37\n",
      "Episode: 181 steps: 109\n",
      "Loss:  3.393053\n",
      "Episode: 182 steps: 44\n",
      "Episode: 183 steps: 38\n",
      "Episode: 184 steps: 49\n",
      "Episode: 185 steps: 28\n",
      "Episode: 186 steps: 36\n",
      "Episode: 187 steps: 35\n",
      "Episode: 188 steps: 62\n",
      "Episode: 189 steps: 36\n",
      "Episode: 190 steps: 30\n",
      "Episode: 191 steps: 48\n",
      "Loss:  462.97906\n",
      "Episode: 192 steps: 28\n",
      "Episode: 193 steps: 35\n",
      "Episode: 194 steps: 60\n",
      "Episode: 195 steps: 45\n",
      "Episode: 196 steps: 60\n",
      "Episode: 197 steps: 37\n",
      "Episode: 198 steps: 46\n",
      "Episode: 199 steps: 35\n",
      "Episode: 200 steps: 28\n",
      "Total score: 40.0\n",
      "Episode: 201 steps: 50\n",
      "Loss:  5.761358\n",
      "Episode: 202 steps: 31\n",
      "Episode: 203 steps: 66\n",
      "Episode: 204 steps: 43\n",
      "Episode: 205 steps: 50\n",
      "Episode: 206 steps: 44\n",
      "Episode: 207 steps: 31\n",
      "Episode: 208 steps: 151\n",
      "Episode: 209 steps: 49\n",
      "Episode: 210 steps: 70\n",
      "Episode: 211 steps: 58\n",
      "Loss:  1.4366375\n",
      "Episode: 212 steps: 44\n",
      "Episode: 213 steps: 57\n",
      "Episode: 214 steps: 54\n",
      "Episode: 215 steps: 38\n",
      "Episode: 216 steps: 42\n",
      "Episode: 217 steps: 60\n",
      "Episode: 218 steps: 36\n",
      "Episode: 219 steps: 60\n",
      "Episode: 220 steps: 152\n",
      "Episode: 221 steps: 37\n",
      "Loss:  2.9169726\n",
      "Episode: 222 steps: 48\n",
      "Episode: 223 steps: 42\n",
      "Episode: 224 steps: 35\n",
      "Episode: 225 steps: 79\n",
      "Episode: 226 steps: 36\n",
      "Episode: 227 steps: 65\n",
      "Episode: 228 steps: 37\n",
      "Episode: 229 steps: 41\n",
      "Episode: 230 steps: 34\n",
      "Episode: 231 steps: 31\n",
      "Loss:  452.8134\n",
      "Episode: 232 steps: 36\n",
      "Episode: 233 steps: 35\n",
      "Episode: 234 steps: 51\n",
      "Episode: 235 steps: 42\n",
      "Episode: 236 steps: 168\n",
      "Episode: 237 steps: 42\n",
      "Episode: 238 steps: 42\n",
      "Episode: 239 steps: 32\n",
      "Episode: 240 steps: 76\n",
      "Episode: 241 steps: 115\n",
      "Loss:  2.046603\n",
      "Episode: 242 steps: 34\n",
      "Episode: 243 steps: 43\n",
      "Episode: 244 steps: 28\n",
      "Episode: 245 steps: 30\n",
      "Episode: 246 steps: 47\n",
      "Episode: 247 steps: 34\n",
      "Episode: 248 steps: 44\n",
      "Episode: 249 steps: 50\n",
      "Episode: 250 steps: 30\n",
      "Total score: 42.0\n",
      "Episode: 251 steps: 41\n",
      "Loss:  216.53506\n",
      "Episode: 252 steps: 67\n",
      "Episode: 253 steps: 35\n",
      "Episode: 254 steps: 36\n",
      "Episode: 255 steps: 60\n",
      "Episode: 256 steps: 46\n",
      "Episode: 257 steps: 41\n",
      "Episode: 258 steps: 67\n",
      "Episode: 259 steps: 47\n",
      "Episode: 260 steps: 31\n",
      "Episode: 261 steps: 124\n",
      "Loss:  90.60849\n",
      "Episode: 262 steps: 113\n",
      "Episode: 263 steps: 35\n",
      "Episode: 264 steps: 36\n",
      "Episode: 265 steps: 73\n",
      "Episode: 266 steps: 27\n",
      "Episode: 267 steps: 35\n",
      "Episode: 268 steps: 93\n",
      "Episode: 269 steps: 44\n",
      "Episode: 270 steps: 53\n",
      "Episode: 271 steps: 63\n",
      "Loss:  2.0776904\n",
      "Episode: 272 steps: 60\n",
      "Episode: 273 steps: 127\n",
      "Episode: 274 steps: 199\n",
      "Episode: 275 steps: 74\n",
      "Episode: 276 steps: 46\n",
      "Episode: 277 steps: 59\n",
      "Episode: 278 steps: 61\n",
      "Episode: 279 steps: 32\n",
      "Episode: 280 steps: 34\n",
      "Episode: 281 steps: 42\n",
      "Loss:  2.139225\n",
      "Episode: 282 steps: 37\n",
      "Episode: 283 steps: 36\n",
      "Episode: 284 steps: 48\n",
      "Episode: 285 steps: 40\n",
      "Episode: 286 steps: 52\n",
      "Episode: 287 steps: 58\n",
      "Episode: 288 steps: 37\n",
      "Episode: 289 steps: 43\n",
      "Episode: 290 steps: 41\n",
      "Episode: 291 steps: 62\n",
      "Loss:  4.515897\n",
      "Episode: 292 steps: 118\n",
      "Episode: 293 steps: 54\n",
      "Episode: 294 steps: 131\n",
      "Episode: 295 steps: 101\n",
      "Episode: 296 steps: 65\n",
      "Episode: 297 steps: 56\n",
      "Episode: 298 steps: 81\n",
      "Episode: 299 steps: 47\n",
      "Episode: 300 steps: 76\n",
      "Total score: 76.0\n",
      "Episode: 301 steps: 53\n",
      "Loss:  2.7398906\n",
      "Episode: 302 steps: 74\n",
      "Episode: 303 steps: 49\n",
      "Episode: 304 steps: 37\n",
      "Episode: 305 steps: 35\n",
      "Episode: 306 steps: 50\n",
      "Episode: 307 steps: 43\n",
      "Episode: 308 steps: 47\n",
      "Episode: 309 steps: 102\n",
      "Episode: 310 steps: 51\n",
      "Episode: 311 steps: 65\n",
      "Loss:  384.65424\n",
      "Episode: 312 steps: 46\n",
      "Episode: 313 steps: 35\n",
      "Episode: 314 steps: 134\n",
      "Episode: 315 steps: 146\n",
      "Episode: 316 steps: 48\n",
      "Episode: 317 steps: 59\n",
      "Episode: 318 steps: 39\n",
      "Episode: 319 steps: 34\n",
      "Episode: 320 steps: 43\n",
      "Episode: 321 steps: 107\n",
      "Loss:  386.17786\n",
      "Episode: 322 steps: 58\n",
      "Episode: 323 steps: 45\n",
      "Episode: 324 steps: 55\n",
      "Episode: 325 steps: 34\n",
      "Episode: 326 steps: 38\n",
      "Episode: 327 steps: 61\n",
      "Episode: 328 steps: 47\n",
      "Episode: 329 steps: 44\n",
      "Episode: 330 steps: 53\n",
      "Episode: 331 steps: 43\n",
      "Loss:  6.675012\n",
      "Episode: 332 steps: 116\n",
      "Episode: 333 steps: 73\n",
      "Episode: 334 steps: 45\n",
      "Episode: 335 steps: 333\n",
      "Episode: 336 steps: 74\n",
      "Episode: 337 steps: 50\n",
      "Episode: 338 steps: 83\n",
      "Episode: 339 steps: 64\n",
      "Episode: 340 steps: 46\n",
      "Episode: 341 steps: 120\n",
      "Loss:  2.7198596\n",
      "Episode: 342 steps: 184\n",
      "Episode: 343 steps: 60\n",
      "Episode: 344 steps: 98\n",
      "Episode: 345 steps: 146\n",
      "Episode: 346 steps: 72\n",
      "Episode: 347 steps: 173\n",
      "Episode: 348 steps: 75\n",
      "Episode: 349 steps: 54\n",
      "Episode: 350 steps: 200\n",
      "Total score: 173.0\n",
      "Episode: 351 steps: 46\n",
      "Loss:  2.518586\n",
      "Episode: 352 steps: 299\n",
      "Episode: 353 steps: 144\n",
      "Episode: 354 steps: 115\n",
      "Episode: 355 steps: 206\n",
      "Episode: 356 steps: 330\n",
      "Episode: 357 steps: 82\n",
      "Episode: 358 steps: 66\n",
      "Episode: 359 steps: 94\n",
      "Episode: 360 steps: 220\n",
      "Episode: 361 steps: 167\n",
      "Loss:  3.3470109\n",
      "Episode: 362 steps: 60\n",
      "Episode: 363 steps: 77\n",
      "Episode: 364 steps: 173\n",
      "Episode: 365 steps: 161\n",
      "Episode: 366 steps: 62\n",
      "Episode: 367 steps: 523\n",
      "Episode: 368 steps: 230\n",
      "Episode: 369 steps: 159\n",
      "Episode: 370 steps: 71\n",
      "Episode: 371 steps: 216\n",
      "Loss:  485.62396\n",
      "Episode: 372 steps: 61\n",
      "Episode: 373 steps: 55\n",
      "Episode: 374 steps: 78\n",
      "Episode: 375 steps: 99\n",
      "Episode: 376 steps: 76\n",
      "Episode: 377 steps: 171\n",
      "Episode: 378 steps: 69\n",
      "Episode: 379 steps: 45\n",
      "Episode: 380 steps: 57\n",
      "Episode: 381 steps: 220\n",
      "Loss:  2.1809216\n",
      "Episode: 382 steps: 75\n",
      "Episode: 383 steps: 53\n",
      "Episode: 384 steps: 65\n",
      "Episode: 385 steps: 192\n",
      "Episode: 386 steps: 60\n",
      "Episode: 387 steps: 212\n",
      "Episode: 388 steps: 66\n",
      "Episode: 389 steps: 272\n",
      "Episode: 390 steps: 64\n",
      "Episode: 391 steps: 245\n",
      "Loss:  121.48659\n",
      "Episode: 392 steps: 184\n",
      "Episode: 393 steps: 57\n",
      "Episode: 394 steps: 320\n",
      "Episode: 395 steps: 59\n",
      "Episode: 396 steps: 71\n",
      "Episode: 397 steps: 59\n",
      "Episode: 398 steps: 81\n",
      "Episode: 399 steps: 47\n",
      "Episode: 400 steps: 326\n",
      "Total score: 167.0\n",
      "Episode: 401 steps: 93\n",
      "Loss:  3.1610932\n",
      "Episode: 402 steps: 160\n",
      "Episode: 403 steps: 231\n",
      "Episode: 404 steps: 53\n",
      "Episode: 405 steps: 154\n",
      "Episode: 406 steps: 70\n",
      "Episode: 407 steps: 70\n",
      "Episode: 408 steps: 87\n",
      "Episode: 409 steps: 255\n",
      "Episode: 410 steps: 356\n",
      "Episode: 411 steps: 109\n",
      "Loss:  0.7255868\n",
      "Episode: 412 steps: 47\n",
      "Episode: 413 steps: 123\n",
      "Episode: 414 steps: 247\n",
      "Episode: 415 steps: 281\n",
      "Episode: 416 steps: 132\n",
      "Episode: 417 steps: 150\n",
      "Episode: 418 steps: 197\n",
      "Episode: 419 steps: 54\n",
      "Episode: 420 steps: 56\n",
      "Episode: 421 steps: 81\n",
      "Loss:  1.9107349\n",
      "Episode: 422 steps: 76\n",
      "Episode: 423 steps: 49\n",
      "Episode: 424 steps: 98\n",
      "Episode: 425 steps: 261\n",
      "Episode: 426 steps: 215\n",
      "Episode: 427 steps: 181\n",
      "Episode: 428 steps: 53\n",
      "Episode: 429 steps: 53\n",
      "Episode: 430 steps: 160\n",
      "Episode: 431 steps: 142\n",
      "Loss:  2.8535953\n",
      "Episode: 432 steps: 60\n",
      "Episode: 433 steps: 186\n",
      "Episode: 434 steps: 161\n",
      "Episode: 435 steps: 263\n",
      "Episode: 436 steps: 52\n",
      "Episode: 437 steps: 190\n",
      "Episode: 438 steps: 57\n",
      "Episode: 439 steps: 63\n",
      "Episode: 440 steps: 70\n",
      "Episode: 441 steps: 55\n",
      "Loss:  3.1310973\n",
      "Episode: 442 steps: 171\n",
      "Episode: 443 steps: 134\n",
      "Episode: 444 steps: 378\n",
      "Episode: 445 steps: 46\n",
      "Episode: 446 steps: 127\n",
      "Episode: 447 steps: 429\n",
      "Episode: 448 steps: 204\n",
      "Episode: 449 steps: 510\n",
      "Episode: 450 steps: 64\n",
      "Total score: 261.0\n",
      "Episode: 451 steps: 63\n",
      "Loss:  2.9511955\n",
      "Episode: 452 steps: 119\n",
      "Episode: 453 steps: 108\n",
      "Episode: 454 steps: 102\n",
      "Episode: 455 steps: 43\n",
      "Episode: 456 steps: 421\n",
      "Episode: 457 steps: 156\n",
      "Episode: 458 steps: 66\n",
      "Episode: 459 steps: 70\n",
      "Episode: 460 steps: 112\n",
      "Episode: 461 steps: 60\n",
      "Loss:  3.3621922\n",
      "Episode: 462 steps: 46\n",
      "Episode: 463 steps: 50\n",
      "Episode: 464 steps: 92\n",
      "Episode: 465 steps: 316\n",
      "Episode: 466 steps: 180\n",
      "Episode: 467 steps: 46\n",
      "Episode: 468 steps: 217\n",
      "Episode: 469 steps: 42\n",
      "Episode: 470 steps: 42\n",
      "Episode: 471 steps: 44\n",
      "Loss:  519.14886\n",
      "Episode: 472 steps: 190\n",
      "Episode: 473 steps: 37\n",
      "Episode: 474 steps: 77\n",
      "Episode: 475 steps: 320\n",
      "Episode: 476 steps: 45\n",
      "Episode: 477 steps: 335\n",
      "Episode: 478 steps: 83\n",
      "Episode: 479 steps: 122\n",
      "Episode: 480 steps: 45\n",
      "Episode: 481 steps: 100\n",
      "Loss:  508.85913\n",
      "Episode: 482 steps: 175\n",
      "Episode: 483 steps: 260\n",
      "Episode: 484 steps: 57\n",
      "Episode: 485 steps: 43\n",
      "Episode: 486 steps: 171\n",
      "Episode: 487 steps: 84\n",
      "Episode: 488 steps: 200\n",
      "Episode: 489 steps: 55\n",
      "Episode: 490 steps: 91\n",
      "Episode: 491 steps: 61\n",
      "Loss:  2.836741\n",
      "Episode: 492 steps: 133\n",
      "Episode: 493 steps: 236\n",
      "Episode: 494 steps: 55\n",
      "Episode: 495 steps: 68\n",
      "Episode: 496 steps: 64\n",
      "Episode: 497 steps: 54\n",
      "Episode: 498 steps: 66\n",
      "Episode: 499 steps: 80\n",
      "Episode: 500 steps: 168\n",
      "Total score: 92.0\n",
      "Episode: 501 steps: 180\n",
      "Loss:  4.122504\n",
      "Episode: 502 steps: 200\n",
      "Episode: 503 steps: 82\n",
      "Episode: 504 steps: 52\n",
      "Episode: 505 steps: 193\n",
      "Episode: 506 steps: 475\n",
      "Episode: 507 steps: 71\n",
      "Episode: 508 steps: 53\n",
      "Episode: 509 steps: 78\n",
      "Episode: 510 steps: 125\n",
      "Episode: 511 steps: 60\n",
      "Loss:  2.1378932\n",
      "Episode: 512 steps: 276\n",
      "Episode: 513 steps: 225\n",
      "Episode: 514 steps: 224\n",
      "Episode: 515 steps: 66\n",
      "Episode: 516 steps: 64\n",
      "Episode: 517 steps: 152\n",
      "Episode: 518 steps: 407\n",
      "Episode: 519 steps: 366\n",
      "Episode: 520 steps: 194\n",
      "Episode: 521 steps: 59\n",
      "Loss:  2.3973267\n",
      "Episode: 522 steps: 123\n",
      "Episode: 523 steps: 91\n",
      "Episode: 524 steps: 55\n",
      "Episode: 525 steps: 69\n",
      "Episode: 526 steps: 63\n",
      "Episode: 527 steps: 78\n",
      "Episode: 528 steps: 171\n",
      "Episode: 529 steps: 59\n",
      "Episode: 530 steps: 242\n",
      "Episode: 531 steps: 149\n",
      "Loss:  1.9034103\n",
      "Episode: 532 steps: 61\n",
      "Episode: 533 steps: 50\n",
      "Episode: 534 steps: 43\n",
      "Episode: 535 steps: 362\n",
      "Episode: 536 steps: 101\n",
      "Episode: 537 steps: 41\n",
      "Episode: 538 steps: 299\n",
      "Episode: 539 steps: 116\n",
      "Episode: 540 steps: 46\n",
      "Episode: 541 steps: 240\n",
      "Loss:  3.1360824\n",
      "Episode: 542 steps: 73\n",
      "Episode: 543 steps: 190\n",
      "Episode: 544 steps: 68\n",
      "Episode: 545 steps: 235\n",
      "Episode: 546 steps: 124\n",
      "Episode: 547 steps: 76\n",
      "Episode: 548 steps: 678\n",
      "Episode: 549 steps: 88\n",
      "Episode: 550 steps: 58\n",
      "Total score: 158.0\n",
      "Episode: 551 steps: 386\n",
      "Loss:  4.2762184\n",
      "Episode: 552 steps: 61\n",
      "Episode: 553 steps: 543\n",
      "Episode: 554 steps: 69\n",
      "Episode: 555 steps: 182\n",
      "Episode: 556 steps: 234\n",
      "Episode: 557 steps: 47\n",
      "Episode: 558 steps: 100\n",
      "Episode: 559 steps: 69\n",
      "Episode: 560 steps: 157\n",
      "Episode: 561 steps: 150\n",
      "Loss:  0.87824315\n",
      "Episode: 562 steps: 72\n",
      "Episode: 563 steps: 68\n",
      "Episode: 564 steps: 69\n",
      "Episode: 565 steps: 62\n",
      "Episode: 566 steps: 63\n",
      "Episode: 567 steps: 231\n",
      "Episode: 568 steps: 307\n",
      "Episode: 569 steps: 54\n",
      "Episode: 570 steps: 424\n",
      "Episode: 571 steps: 143\n",
      "Loss:  1.9455897\n",
      "Episode: 572 steps: 78\n",
      "Episode: 573 steps: 82\n",
      "Episode: 574 steps: 67\n",
      "Episode: 575 steps: 61\n",
      "Episode: 576 steps: 92\n",
      "Episode: 577 steps: 90\n",
      "Episode: 578 steps: 134\n",
      "Episode: 579 steps: 67\n",
      "Episode: 580 steps: 320\n",
      "Episode: 581 steps: 95\n",
      "Loss:  1.5623683\n",
      "Episode: 582 steps: 133\n",
      "Episode: 583 steps: 75\n",
      "Episode: 584 steps: 440\n",
      "Episode: 585 steps: 79\n",
      "Episode: 586 steps: 74\n",
      "Episode: 587 steps: 88\n",
      "Episode: 588 steps: 67\n",
      "Episode: 589 steps: 276\n",
      "Episode: 590 steps: 63\n",
      "Episode: 591 steps: 112\n",
      "Loss:  3.212131\n",
      "Episode: 592 steps: 466\n",
      "Episode: 593 steps: 65\n",
      "Episode: 594 steps: 173\n",
      "Episode: 595 steps: 376\n",
      "Episode: 596 steps: 329\n",
      "Episode: 597 steps: 79\n",
      "Episode: 598 steps: 299\n",
      "Episode: 599 steps: 288\n",
      "Episode: 600 steps: 72\n",
      "Total score: 115.0\n",
      "Episode: 601 steps: 190\n",
      "Loss:  2.5163379\n",
      "Episode: 602 steps: 83\n",
      "Episode: 603 steps: 108\n",
      "Episode: 604 steps: 283\n",
      "Episode: 605 steps: 52\n",
      "Episode: 606 steps: 88\n",
      "Episode: 607 steps: 77\n",
      "Episode: 608 steps: 173\n",
      "Episode: 609 steps: 423\n",
      "Episode: 610 steps: 102\n",
      "Episode: 611 steps: 70\n",
      "Loss:  1.6036708\n",
      "Episode: 612 steps: 370\n",
      "Episode: 613 steps: 48\n",
      "Episode: 614 steps: 74\n",
      "Episode: 615 steps: 175\n",
      "Episode: 616 steps: 72\n",
      "Episode: 617 steps: 220\n",
      "Episode: 618 steps: 507\n",
      "Episode: 619 steps: 118\n",
      "Episode: 620 steps: 395\n",
      "Episode: 621 steps: 95\n",
      "Loss:  1.0050995\n",
      "Episode: 622 steps: 74\n",
      "Episode: 623 steps: 88\n",
      "Episode: 624 steps: 68\n",
      "Episode: 625 steps: 86\n",
      "Episode: 626 steps: 89\n",
      "Episode: 627 steps: 64\n",
      "Episode: 628 steps: 65\n",
      "Episode: 629 steps: 108\n",
      "Episode: 630 steps: 599\n",
      "Episode: 631 steps: 96\n",
      "Loss:  1.1098725\n",
      "Episode: 632 steps: 77\n",
      "Episode: 633 steps: 122\n",
      "Episode: 634 steps: 66\n",
      "Episode: 635 steps: 55\n",
      "Episode: 636 steps: 73\n",
      "Episode: 637 steps: 57\n",
      "Episode: 638 steps: 65\n",
      "Episode: 639 steps: 63\n",
      "Episode: 640 steps: 85\n",
      "Episode: 641 steps: 70\n",
      "Loss:  0.33107585\n",
      "Episode: 642 steps: 247\n",
      "Episode: 643 steps: 58\n",
      "Episode: 644 steps: 62\n",
      "Episode: 645 steps: 121\n",
      "Episode: 646 steps: 84\n",
      "Episode: 647 steps: 332\n",
      "Episode: 648 steps: 68\n",
      "Episode: 649 steps: 173\n",
      "Episode: 650 steps: 119\n",
      "Total score: 68.0\n",
      "Episode: 651 steps: 100\n",
      "Loss:  0.75995386\n",
      "Episode: 652 steps: 84\n",
      "Episode: 653 steps: 88\n",
      "Episode: 654 steps: 76\n",
      "Episode: 655 steps: 68\n",
      "Episode: 656 steps: 390\n",
      "Episode: 657 steps: 65\n",
      "Episode: 658 steps: 74\n",
      "Episode: 659 steps: 284\n",
      "Episode: 660 steps: 690\n",
      "Episode: 661 steps: 233\n",
      "Loss:  464.79803\n",
      "Episode: 662 steps: 751\n",
      "Episode: 663 steps: 85\n",
      "Episode: 664 steps: 86\n",
      "Episode: 665 steps: 95\n",
      "Episode: 666 steps: 186\n",
      "Episode: 667 steps: 283\n",
      "Episode: 668 steps: 69\n",
      "Episode: 669 steps: 198\n",
      "Episode: 670 steps: 292\n",
      "Episode: 671 steps: 230\n",
      "Loss:  1.75354\n",
      "Episode: 672 steps: 126\n",
      "Episode: 673 steps: 48\n",
      "Episode: 674 steps: 87\n",
      "Episode: 675 steps: 139\n",
      "Episode: 676 steps: 114\n",
      "Episode: 677 steps: 168\n",
      "Episode: 678 steps: 308\n",
      "Episode: 679 steps: 90\n",
      "Episode: 680 steps: 198\n",
      "Episode: 681 steps: 244\n",
      "Loss:  1.5763586\n",
      "Episode: 682 steps: 104\n",
      "Episode: 683 steps: 343\n",
      "Episode: 684 steps: 514\n",
      "Episode: 685 steps: 256\n",
      "Episode: 686 steps: 93\n",
      "Episode: 687 steps: 272\n",
      "Episode: 688 steps: 291\n",
      "Episode: 689 steps: 351\n",
      "Episode: 690 steps: 46\n",
      "Episode: 691 steps: 460\n",
      "Loss:  0.68947685\n",
      "Episode: 692 steps: 430\n",
      "Episode: 693 steps: 197\n",
      "Episode: 694 steps: 293\n",
      "Episode: 695 steps: 415\n",
      "Episode: 696 steps: 200\n",
      "Episode: 697 steps: 298\n",
      "Episode: 698 steps: 115\n",
      "Episode: 699 steps: 50\n",
      "Episode: 700 steps: 164\n",
      "Total score: 83.0\n",
      "Episode: 701 steps: 65\n",
      "Loss:  1.3235824\n",
      "Episode: 702 steps: 243\n",
      "Episode: 703 steps: 75\n",
      "Episode: 704 steps: 79\n",
      "Episode: 705 steps: 528\n",
      "Episode: 706 steps: 101\n",
      "Episode: 707 steps: 50\n",
      "Episode: 708 steps: 113\n",
      "Episode: 709 steps: 168\n",
      "Episode: 710 steps: 258\n",
      "Episode: 711 steps: 123\n",
      "Loss:  0.7720607\n",
      "Episode: 712 steps: 235\n",
      "Episode: 713 steps: 103\n",
      "Episode: 714 steps: 105\n",
      "Episode: 715 steps: 107\n",
      "Episode: 716 steps: 65\n",
      "Episode: 717 steps: 203\n",
      "Episode: 718 steps: 87\n",
      "Episode: 719 steps: 487\n",
      "Episode: 720 steps: 89\n",
      "Episode: 721 steps: 240\n",
      "Loss:  0.7879584\n",
      "Episode: 722 steps: 45\n",
      "Episode: 723 steps: 679\n",
      "Episode: 724 steps: 97\n",
      "Episode: 725 steps: 328\n",
      "Episode: 726 steps: 553\n",
      "Episode: 727 steps: 121\n",
      "Episode: 728 steps: 83\n",
      "Episode: 729 steps: 159\n",
      "Episode: 730 steps: 83\n",
      "Episode: 731 steps: 507\n",
      "Loss:  1.5126588\n",
      "Episode: 732 steps: 104\n",
      "Episode: 733 steps: 332\n",
      "Episode: 734 steps: 108\n",
      "Episode: 735 steps: 113\n",
      "Episode: 736 steps: 85\n",
      "Episode: 737 steps: 481\n",
      "Episode: 738 steps: 90\n",
      "Episode: 739 steps: 102\n",
      "Episode: 740 steps: 409\n",
      "Episode: 741 steps: 107\n",
      "Loss:  1.156009\n",
      "Episode: 742 steps: 295\n",
      "Episode: 743 steps: 90\n",
      "Episode: 744 steps: 112\n",
      "Episode: 745 steps: 84\n",
      "Episode: 746 steps: 795\n",
      "Episode: 747 steps: 71\n",
      "Episode: 748 steps: 73\n",
      "Episode: 749 steps: 245\n",
      "Episode: 750 steps: 77\n",
      "Total score: 98.0\n",
      "Episode: 751 steps: 769\n",
      "Loss:  0.621335\n",
      "Episode: 752 steps: 84\n",
      "Episode: 753 steps: 88\n",
      "Episode: 754 steps: 432\n",
      "Episode: 755 steps: 75\n",
      "Episode: 756 steps: 108\n",
      "Episode: 757 steps: 112\n",
      "Episode: 758 steps: 595\n",
      "Episode: 759 steps: 71\n",
      "Episode: 760 steps: 85\n",
      "Episode: 761 steps: 82\n",
      "Loss:  0.58187646\n",
      "Episode: 762 steps: 395\n",
      "Episode: 763 steps: 102\n",
      "Episode: 764 steps: 82\n",
      "Episode: 765 steps: 83\n",
      "Episode: 766 steps: 118\n",
      "Episode: 767 steps: 123\n",
      "Episode: 768 steps: 74\n",
      "Episode: 769 steps: 98\n",
      "Episode: 770 steps: 78\n",
      "Episode: 771 steps: 125\n",
      "Loss:  1.1817871\n",
      "Episode: 772 steps: 294\n",
      "Episode: 773 steps: 346\n",
      "Episode: 774 steps: 201\n",
      "Episode: 775 steps: 624\n",
      "Episode: 776 steps: 497\n",
      "Episode: 777 steps: 561\n",
      "Episode: 778 steps: 623\n",
      "Episode: 779 steps: 956\n",
      "Episode: 780 steps: 434\n",
      "Episode: 781 steps: 123\n",
      "Loss:  0.093660474\n",
      "Episode: 782 steps: 97\n",
      "Episode: 783 steps: 1072\n",
      "Episode: 784 steps: 103\n",
      "Episode: 785 steps: 625\n",
      "Episode: 786 steps: 141\n",
      "Episode: 787 steps: 227\n",
      "Episode: 788 steps: 116\n",
      "Episode: 789 steps: 800\n",
      "Episode: 790 steps: 101\n",
      "Episode: 791 steps: 252\n",
      "Loss:  0.098664105\n",
      "Episode: 792 steps: 440\n",
      "Episode: 793 steps: 748\n",
      "Episode: 794 steps: 212\n",
      "Episode: 795 steps: 212\n",
      "Episode: 796 steps: 783\n",
      "Episode: 797 steps: 1116\n",
      "Episode: 798 steps: 492\n",
      "Episode: 799 steps: 99\n",
      "Episode: 800 steps: 105\n",
      "Total score: 241.0\n",
      "Episode: 801 steps: 178\n",
      "Loss:  0.46011963\n",
      "Episode: 802 steps: 107\n",
      "Episode: 803 steps: 135\n",
      "Episode: 804 steps: 94\n",
      "Episode: 805 steps: 102\n",
      "Episode: 806 steps: 109\n",
      "Episode: 807 steps: 532\n",
      "Episode: 808 steps: 385\n",
      "Episode: 809 steps: 124\n",
      "Episode: 810 steps: 236\n",
      "Episode: 811 steps: 219\n",
      "Loss:  1.4770204\n",
      "Episode: 812 steps: 531\n",
      "Episode: 813 steps: 57\n",
      "Episode: 814 steps: 455\n",
      "Episode: 815 steps: 72\n",
      "Episode: 816 steps: 62\n",
      "Episode: 817 steps: 352\n",
      "Episode: 818 steps: 480\n",
      "Episode: 819 steps: 442\n",
      "Episode: 820 steps: 333\n",
      "Episode: 821 steps: 503\n",
      "Loss:  0.10757387\n",
      "Episode: 822 steps: 363\n",
      "Episode: 823 steps: 150\n",
      "Episode: 824 steps: 665\n",
      "Episode: 825 steps: 185\n",
      "Episode: 826 steps: 1119\n",
      "Episode: 827 steps: 221\n",
      "Episode: 828 steps: 116\n",
      "Episode: 829 steps: 100\n",
      "Episode: 830 steps: 375\n",
      "Episode: 831 steps: 1055\n",
      "Loss:  0.334911\n",
      "Episode: 832 steps: 388\n",
      "Episode: 833 steps: 246\n",
      "Episode: 834 steps: 549\n",
      "Episode: 835 steps: 274\n",
      "Episode: 836 steps: 149\n",
      "Episode: 837 steps: 239\n",
      "Episode: 838 steps: 98\n",
      "Episode: 839 steps: 137\n",
      "Episode: 840 steps: 95\n",
      "Episode: 841 steps: 1077\n",
      "Loss:  0.6046434\n",
      "Episode: 842 steps: 162\n",
      "Episode: 843 steps: 1325\n",
      "Episode: 844 steps: 473\n",
      "Episode: 845 steps: 84\n",
      "Episode: 846 steps: 132\n",
      "Episode: 847 steps: 78\n",
      "Episode: 848 steps: 316\n",
      "Episode: 849 steps: 323\n",
      "Episode: 850 steps: 92\n",
      "Total score: 94.0\n",
      "Episode: 851 steps: 132\n",
      "Loss:  0.5687947\n",
      "Episode: 852 steps: 370\n",
      "Episode: 853 steps: 205\n",
      "Episode: 854 steps: 125\n",
      "Episode: 855 steps: 114\n",
      "Episode: 856 steps: 269\n",
      "Episode: 857 steps: 142\n",
      "Episode: 858 steps: 114\n",
      "Episode: 859 steps: 100\n",
      "Episode: 860 steps: 1320\n",
      "Episode: 861 steps: 87\n",
      "Loss:  0.52194685\n",
      "Episode: 862 steps: 581\n",
      "Episode: 863 steps: 327\n",
      "Episode: 864 steps: 2365\n",
      "Episode: 865 steps: 265\n",
      "Episode: 866 steps: 417\n",
      "Episode: 867 steps: 360\n",
      "Episode: 868 steps: 1527\n",
      "Episode: 869 steps: 1179\n",
      "Episode: 870 steps: 553\n",
      "Episode: 871 steps: 151\n",
      "Loss:  1.7852347\n",
      "Episode: 872 steps: 199\n",
      "Episode: 873 steps: 108\n",
      "Episode: 874 steps: 279\n",
      "Episode: 875 steps: 88\n",
      "Episode: 876 steps: 225\n",
      "Episode: 877 steps: 778\n",
      "Episode: 878 steps: 257\n",
      "Episode: 879 steps: 84\n",
      "Episode: 880 steps: 270\n",
      "Episode: 881 steps: 80\n",
      "Loss:  0.23323521\n",
      "Episode: 882 steps: 152\n",
      "Episode: 883 steps: 88\n",
      "Episode: 884 steps: 326\n",
      "Episode: 885 steps: 401\n",
      "Episode: 886 steps: 112\n",
      "Episode: 887 steps: 166\n",
      "Episode: 888 steps: 403\n",
      "Episode: 889 steps: 437\n",
      "Episode: 890 steps: 107\n",
      "Episode: 891 steps: 1425\n",
      "Loss:  0.17024109\n",
      "Episode: 892 steps: 803\n",
      "Episode: 893 steps: 116\n",
      "Episode: 894 steps: 604\n",
      "Episode: 895 steps: 111\n",
      "Episode: 896 steps: 86\n",
      "Episode: 897 steps: 99\n",
      "Episode: 898 steps: 86\n",
      "Episode: 899 steps: 100\n",
      "Episode: 900 steps: 145\n",
      "Total score: 431.0\n",
      "Episode: 901 steps: 89\n",
      "Loss:  1.6247566\n",
      "Episode: 902 steps: 553\n",
      "Episode: 903 steps: 88\n",
      "Episode: 904 steps: 144\n",
      "Episode: 905 steps: 3984\n",
      "Episode: 906 steps: 97\n",
      "Episode: 907 steps: 229\n",
      "Episode: 908 steps: 2546\n",
      "Episode: 909 steps: 98\n",
      "Episode: 910 steps: 843\n",
      "Episode: 911 steps: 100\n",
      "Loss:  0.1459172\n",
      "Episode: 912 steps: 846\n",
      "Episode: 913 steps: 534\n",
      "Episode: 914 steps: 1671\n",
      "Episode: 915 steps: 95\n",
      "Episode: 916 steps: 244\n",
      "Episode: 917 steps: 343\n",
      "Episode: 918 steps: 2174\n",
      "Episode: 919 steps: 979\n",
      "Episode: 920 steps: 450\n",
      "Episode: 921 steps: 436\n",
      "Loss:  0.3313844\n",
      "Episode: 922 steps: 622\n",
      "Episode: 923 steps: 2580\n",
      "Episode: 924 steps: 240\n",
      "Episode: 925 steps: 159\n",
      "Episode: 926 steps: 1813\n",
      "Episode: 927 steps: 276\n",
      "Episode: 928 steps: 1601\n",
      "Episode: 929 steps: 318\n",
      "Episode: 930 steps: 141\n",
      "Episode: 931 steps: 107\n",
      "Loss:  0.05076326\n",
      "Episode: 932 steps: 263\n",
      "Episode: 933 steps: 1544\n",
      "Episode: 934 steps: 280\n",
      "Episode: 935 steps: 109\n",
      "Episode: 936 steps: 90\n",
      "Episode: 937 steps: 88\n",
      "Episode: 938 steps: 91\n",
      "Episode: 939 steps: 576\n",
      "Episode: 940 steps: 81\n",
      "Episode: 941 steps: 192\n",
      "Loss:  0.04824444\n",
      "Episode: 942 steps: 3248\n",
      "Episode: 943 steps: 282\n",
      "Episode: 944 steps: 92\n",
      "Episode: 945 steps: 85\n",
      "Episode: 946 steps: 2724\n",
      "Episode: 947 steps: 331\n",
      "Episode: 948 steps: 86\n",
      "Episode: 949 steps: 2441\n",
      "Episode: 950 steps: 801\n",
      "Total score: 574.0\n",
      "Episode: 951 steps: 596\n",
      "Loss:  0.06671028\n",
      "Episode: 952 steps: 366\n",
      "Episode: 953 steps: 308\n",
      "Episode: 954 steps: 458\n",
      "Episode: 955 steps: 336\n",
      "Episode: 956 steps: 1076\n",
      "Episode: 957 steps: 100\n",
      "Episode: 958 steps: 1099\n",
      "Episode: 959 steps: 121\n",
      "Episode: 960 steps: 115\n",
      "Episode: 961 steps: 106\n",
      "Loss:  0.2879625\n",
      "Episode: 962 steps: 330\n",
      "Episode: 963 steps: 361\n",
      "Episode: 964 steps: 279\n",
      "Episode: 965 steps: 352\n",
      "Episode: 966 steps: 746\n",
      "Episode: 967 steps: 1521\n",
      "Episode: 968 steps: 645\n",
      "Episode: 969 steps: 112\n",
      "Episode: 970 steps: 94\n",
      "Episode: 971 steps: 258\n",
      "Loss:  0.1430552\n",
      "Episode: 972 steps: 390\n",
      "Episode: 973 steps: 484\n",
      "Episode: 974 steps: 886\n",
      "Episode: 975 steps: 120\n",
      "Episode: 976 steps: 476\n",
      "Episode: 977 steps: 314\n",
      "Episode: 978 steps: 258\n",
      "Episode: 979 steps: 416\n",
      "Episode: 980 steps: 283\n",
      "Episode: 981 steps: 670\n",
      "Loss:  0.29443362\n",
      "Episode: 982 steps: 115\n",
      "Episode: 983 steps: 778\n",
      "Episode: 984 steps: 645\n",
      "Episode: 985 steps: 533\n",
      "Episode: 986 steps: 308\n",
      "Episode: 987 steps: 266\n",
      "Episode: 988 steps: 899\n",
      "Episode: 989 steps: 743\n",
      "Episode: 990 steps: 564\n",
      "Episode: 991 steps: 125\n",
      "Loss:  0.01840949\n",
      "Episode: 992 steps: 126\n",
      "Episode: 993 steps: 105\n",
      "Episode: 994 steps: 157\n",
      "Episode: 995 steps: 100\n",
      "Episode: 996 steps: 1707\n",
      "Episode: 997 steps: 360\n",
      "Episode: 998 steps: 151\n",
      "Episode: 999 steps: 1809\n",
      "Episode: 1000 steps: 340\n",
      "Total score: 604.0\n",
      "Episode: 1001 steps: 1524\n",
      "Loss:  0.24104638\n",
      "Episode: 1002 steps: 775\n",
      "Episode: 1003 steps: 125\n",
      "Episode: 1004 steps: 364\n",
      "Episode: 1005 steps: 115\n",
      "Episode: 1006 steps: 130\n",
      "Episode: 1007 steps: 1170\n",
      "Episode: 1008 steps: 119\n",
      "Episode: 1009 steps: 853\n",
      "Episode: 1010 steps: 173\n",
      "Episode: 1011 steps: 110\n",
      "Loss:  0.4441498\n",
      "Episode: 1012 steps: 391\n",
      "Episode: 1013 steps: 118\n",
      "Episode: 1014 steps: 969\n",
      "Episode: 1015 steps: 589\n",
      "Episode: 1016 steps: 346\n",
      "Episode: 1017 steps: 604\n",
      "Episode: 1018 steps: 336\n",
      "Episode: 1019 steps: 377\n",
      "Episode: 1020 steps: 217\n",
      "Episode: 1021 steps: 322\n",
      "Loss:  0.19647609\n",
      "Episode: 1022 steps: 578\n",
      "Episode: 1023 steps: 703\n",
      "Episode: 1024 steps: 94\n",
      "Episode: 1025 steps: 95\n",
      "Episode: 1026 steps: 287\n",
      "Episode: 1027 steps: 454\n",
      "Episode: 1028 steps: 120\n",
      "Episode: 1029 steps: 115\n",
      "Episode: 1030 steps: 555\n",
      "Episode: 1031 steps: 168\n",
      "Loss:  0.119839214\n",
      "Episode: 1032 steps: 67\n",
      "Episode: 1033 steps: 85\n",
      "Episode: 1034 steps: 626\n",
      "Episode: 1035 steps: 79\n",
      "Episode: 1036 steps: 85\n",
      "Episode: 1037 steps: 102\n",
      "Episode: 1038 steps: 77\n",
      "Episode: 1039 steps: 74\n",
      "Episode: 1040 steps: 110\n",
      "Episode: 1041 steps: 74\n",
      "Loss:  0.048120886\n",
      "Episode: 1042 steps: 82\n",
      "Episode: 1043 steps: 101\n",
      "Episode: 1044 steps: 2769\n",
      "Episode: 1045 steps: 662\n",
      "Episode: 1046 steps: 266\n",
      "Episode: 1047 steps: 93\n",
      "Episode: 1048 steps: 1740\n",
      "Episode: 1049 steps: 385\n",
      "Episode: 1050 steps: 120\n",
      "Total score: 704.0\n",
      "Episode: 1051 steps: 662\n",
      "Loss:  0.9714781\n",
      "Episode: 1052 steps: 827\n",
      "Episode: 1053 steps: 2703\n",
      "Episode: 1054 steps: 4068\n",
      "Episode: 1055 steps: 1171\n",
      "Episode: 1056 steps: 347\n",
      "Episode: 1057 steps: 103\n",
      "Episode: 1058 steps: 229\n",
      "Episode: 1059 steps: 511\n",
      "Episode: 1060 steps: 114\n",
      "Episode: 1061 steps: 322\n",
      "Loss:  0.21550569\n",
      "Episode: 1062 steps: 220\n",
      "Episode: 1063 steps: 1883\n",
      "Episode: 1064 steps: 206\n",
      "Episode: 1065 steps: 200\n",
      "Episode: 1066 steps: 120\n",
      "Episode: 1067 steps: 105\n",
      "Episode: 1068 steps: 137\n",
      "Episode: 1069 steps: 198\n",
      "Episode: 1070 steps: 218\n",
      "Episode: 1071 steps: 75\n",
      "Loss:  0.048727747\n",
      "Episode: 1072 steps: 98\n",
      "Episode: 1073 steps: 758\n",
      "Episode: 1074 steps: 107\n",
      "Episode: 1075 steps: 209\n",
      "Episode: 1076 steps: 1397\n",
      "Episode: 1077 steps: 487\n",
      "Episode: 1078 steps: 250\n",
      "Episode: 1079 steps: 108\n",
      "Episode: 1080 steps: 618\n",
      "Episode: 1081 steps: 413\n",
      "Loss:  0.13254975\n",
      "Episode: 1082 steps: 357\n",
      "Episode: 1083 steps: 1004\n",
      "Episode: 1084 steps: 1130\n",
      "Episode: 1085 steps: 1228\n",
      "Episode: 1086 steps: 818\n",
      "Episode: 1087 steps: 331\n",
      "Episode: 1088 steps: 706\n",
      "Episode: 1089 steps: 87\n",
      "Episode: 1090 steps: 261\n",
      "Episode: 1091 steps: 1299\n",
      "Loss:  0.03830946\n",
      "Episode: 1092 steps: 315\n",
      "Episode: 1093 steps: 281\n",
      "Episode: 1094 steps: 318\n",
      "Episode: 1095 steps: 354\n",
      "Episode: 1096 steps: 282\n",
      "Episode: 1097 steps: 259\n",
      "Episode: 1098 steps: 1372\n",
      "Episode: 1099 steps: 111\n",
      "Episode: 1100 steps: 252\n",
      "Total score: 544.0\n",
      "Episode: 1101 steps: 806\n",
      "Loss:  0.07167993\n",
      "Episode: 1102 steps: 529\n",
      "Episode: 1103 steps: 318\n",
      "Episode: 1104 steps: 1342\n",
      "Episode: 1105 steps: 1095\n",
      "Episode: 1106 steps: 105\n",
      "Episode: 1107 steps: 937\n",
      "Episode: 1108 steps: 382\n",
      "Episode: 1109 steps: 232\n",
      "Episode: 1110 steps: 450\n",
      "Episode: 1111 steps: 658\n",
      "Loss:  0.17572734\n",
      "Episode: 1112 steps: 719\n",
      "Episode: 1113 steps: 84\n",
      "Episode: 1114 steps: 305\n",
      "Episode: 1115 steps: 815\n",
      "Episode: 1116 steps: 582\n",
      "Episode: 1117 steps: 101\n",
      "Episode: 1118 steps: 250\n",
      "Episode: 1119 steps: 563\n",
      "Episode: 1120 steps: 883\n",
      "Episode: 1121 steps: 262\n",
      "Loss:  0.08642156\n",
      "Episode: 1122 steps: 83\n",
      "Episode: 1123 steps: 922\n",
      "Episode: 1124 steps: 998\n",
      "Episode: 1125 steps: 107\n",
      "Episode: 1126 steps: 83\n",
      "Episode: 1127 steps: 946\n",
      "Episode: 1128 steps: 80\n",
      "Episode: 1129 steps: 647\n",
      "Episode: 1130 steps: 251\n",
      "Episode: 1131 steps: 654\n",
      "Loss:  0.1040145\n",
      "Episode: 1132 steps: 106\n",
      "Episode: 1133 steps: 220\n",
      "Episode: 1134 steps: 336\n",
      "Episode: 1135 steps: 626\n",
      "Episode: 1136 steps: 120\n",
      "Episode: 1137 steps: 320\n",
      "Episode: 1138 steps: 612\n",
      "Episode: 1139 steps: 108\n",
      "Episode: 1140 steps: 367\n",
      "Episode: 1141 steps: 646\n",
      "Loss:  0.08655079\n",
      "Episode: 1142 steps: 120\n",
      "Episode: 1143 steps: 94\n",
      "Episode: 1144 steps: 462\n",
      "Episode: 1145 steps: 311\n",
      "Episode: 1146 steps: 88\n",
      "Episode: 1147 steps: 314\n",
      "Episode: 1148 steps: 359\n",
      "Episode: 1149 steps: 2598\n",
      "Episode: 1150 steps: 1886\n",
      "Total score: 297.0\n",
      "Episode: 1151 steps: 108\n",
      "Loss:  1.4997691\n",
      "Episode: 1152 steps: 1542\n",
      "Episode: 1153 steps: 2046\n",
      "Episode: 1154 steps: 101\n",
      "Episode: 1155 steps: 396\n",
      "Episode: 1156 steps: 1550\n",
      "Episode: 1157 steps: 331\n",
      "Episode: 1158 steps: 121\n",
      "Episode: 1159 steps: 305\n",
      "Episode: 1160 steps: 100\n",
      "Episode: 1161 steps: 94\n",
      "Loss:  0.06778639\n",
      "Episode: 1162 steps: 555\n",
      "Episode: 1163 steps: 1257\n",
      "Episode: 1164 steps: 289\n",
      "Episode: 1165 steps: 1534\n",
      "Episode: 1166 steps: 321\n",
      "Episode: 1167 steps: 128\n",
      "Episode: 1168 steps: 532\n",
      "Episode: 1169 steps: 1488\n",
      "Episode: 1170 steps: 1097\n",
      "Episode: 1171 steps: 258\n",
      "Loss:  0.11496766\n",
      "Episode: 1172 steps: 246\n",
      "Episode: 1173 steps: 434\n",
      "Episode: 1174 steps: 1698\n",
      "Episode: 1175 steps: 350\n",
      "Episode: 1176 steps: 479\n",
      "Episode: 1177 steps: 137\n",
      "Episode: 1178 steps: 108\n",
      "Episode: 1179 steps: 620\n",
      "Episode: 1180 steps: 150\n",
      "Episode: 1181 steps: 685\n",
      "Loss:  0.058668006\n",
      "Episode: 1182 steps: 550\n",
      "Episode: 1183 steps: 108\n",
      "Episode: 1184 steps: 430\n",
      "Episode: 1185 steps: 737\n",
      "Episode: 1186 steps: 323\n",
      "Episode: 1187 steps: 330\n",
      "Episode: 1188 steps: 118\n",
      "Episode: 1189 steps: 113\n",
      "Episode: 1190 steps: 116\n",
      "Episode: 1191 steps: 611\n",
      "Loss:  0.107217744\n",
      "Episode: 1192 steps: 336\n",
      "Episode: 1193 steps: 370\n",
      "Episode: 1194 steps: 113\n",
      "Episode: 1195 steps: 288\n",
      "Episode: 1196 steps: 896\n",
      "Episode: 1197 steps: 321\n",
      "Episode: 1198 steps: 92\n",
      "Episode: 1199 steps: 641\n",
      "Episode: 1200 steps: 308\n",
      "Total score: 1266.0\n",
      "Episode: 1201 steps: 336\n",
      "Loss:  0.030952811\n",
      "Episode: 1202 steps: 370\n",
      "Episode: 1203 steps: 259\n",
      "Episode: 1204 steps: 451\n",
      "Episode: 1205 steps: 300\n",
      "Episode: 1206 steps: 552\n",
      "Episode: 1207 steps: 85\n",
      "Episode: 1208 steps: 250\n",
      "Episode: 1209 steps: 1039\n",
      "Episode: 1210 steps: 348\n",
      "Episode: 1211 steps: 640\n",
      "Loss:  0.20592591\n",
      "Episode: 1212 steps: 114\n",
      "Episode: 1213 steps: 366\n",
      "Episode: 1214 steps: 412\n",
      "Episode: 1215 steps: 976\n",
      "Episode: 1216 steps: 767\n",
      "Episode: 1217 steps: 1604\n",
      "Episode: 1218 steps: 298\n",
      "Episode: 1219 steps: 486\n",
      "Episode: 1220 steps: 97\n",
      "Episode: 1221 steps: 322\n",
      "Loss:  0.21095619\n",
      "Episode: 1222 steps: 534\n",
      "Episode: 1223 steps: 252\n",
      "Episode: 1224 steps: 413\n",
      "Episode: 1225 steps: 255\n",
      "Episode: 1226 steps: 129\n",
      "Episode: 1227 steps: 240\n",
      "Episode: 1228 steps: 160\n",
      "Episode: 1229 steps: 257\n",
      "Episode: 1230 steps: 208\n",
      "Episode: 1231 steps: 268\n",
      "Loss:  0.46670836\n",
      "Episode: 1232 steps: 694\n",
      "Episode: 1233 steps: 530\n",
      "Episode: 1234 steps: 1665\n",
      "Episode: 1235 steps: 449\n",
      "Episode: 1236 steps: 709\n",
      "Episode: 1237 steps: 1225\n",
      "Episode: 1238 steps: 119\n",
      "Episode: 1239 steps: 469\n",
      "Episode: 1240 steps: 2726\n",
      "Episode: 1241 steps: 448\n",
      "Loss:  1.0129766\n",
      "Episode: 1242 steps: 119\n",
      "Episode: 1243 steps: 111\n",
      "Episode: 1244 steps: 264\n",
      "Episode: 1245 steps: 120\n",
      "Episode: 1246 steps: 370\n",
      "Episode: 1247 steps: 124\n",
      "Episode: 1248 steps: 532\n",
      "Episode: 1249 steps: 643\n",
      "Episode: 1250 steps: 337\n",
      "Total score: 395.0\n",
      "Episode: 1251 steps: 257\n",
      "Loss:  0.025974562\n",
      "Episode: 1252 steps: 530\n",
      "Episode: 1253 steps: 340\n",
      "Episode: 1254 steps: 794\n",
      "Episode: 1255 steps: 852\n",
      "Episode: 1256 steps: 477\n",
      "Episode: 1257 steps: 416\n",
      "Episode: 1258 steps: 479\n",
      "Episode: 1259 steps: 468\n",
      "Episode: 1260 steps: 397\n",
      "Episode: 1261 steps: 491\n",
      "Loss:  0.042869065\n",
      "Episode: 1262 steps: 596\n",
      "Episode: 1263 steps: 720\n",
      "Episode: 1264 steps: 374\n",
      "Episode: 1265 steps: 376\n",
      "Episode: 1266 steps: 365\n",
      "Episode: 1267 steps: 342\n",
      "Episode: 1268 steps: 504\n",
      "Episode: 1269 steps: 337\n",
      "Episode: 1270 steps: 110\n",
      "Episode: 1271 steps: 91\n",
      "Loss:  0.86710006\n",
      "Episode: 1272 steps: 347\n",
      "Episode: 1273 steps: 260\n",
      "Episode: 1274 steps: 254\n",
      "Episode: 1275 steps: 318\n",
      "Episode: 1276 steps: 1022\n",
      "Episode: 1277 steps: 128\n",
      "Episode: 1278 steps: 235\n",
      "Episode: 1279 steps: 259\n",
      "Episode: 1280 steps: 247\n",
      "Episode: 1281 steps: 440\n",
      "Loss:  0.09921551\n",
      "Episode: 1282 steps: 429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/py/1492cdrd3mqfsq8sn558ppb80000gn/T/ipykernel_27656/451043146.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/py/1492cdrd3mqfsq8sn558ppb80000gn/T/ipykernel_27656/2138527500.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmainDQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/py/1492cdrd3mqfsq8sn558ppb80000gn/T/ipykernel_27656/2868268092.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    939\u001b[0m                     \u001b[0;34m\"layers will not see the mask.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0;31m# Destroy call context if we created it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_reset_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[1;32m     43\u001b[0m                 \u001b[0mcall_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.call()\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# Fallback: Just apply the layer sequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This typically happens if `inputs` is a nested struct.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten_to_reference_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         outputs = self._run_through_graph(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moperation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/ops/function.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcall_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_has_training_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    939\u001b[0m                     \u001b[0;34m\"layers will not see the mask.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0;31m# Destroy call context if we created it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_reset_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[1;32m     43\u001b[0m                 \u001b[0mcall_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.call()\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/layers/core/dense.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   3441\u001b[0m         \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3442\u001b[0m     \"\"\"\n\u001b[1;32m   3443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3444\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3445\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx1_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx2_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mx2_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mx1_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, grad_a, grad_b, name)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0mgrad_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3655\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3657\u001b[0;31m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[1;32m   3658\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3659\u001b[0m             \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3660\u001b[0m             \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gym/lib/python3.12/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(a, b, transpose_a, transpose_b, grad_a, grad_b, name)\u001b[0m\n\u001b[1;32m   6232\u001b[0m         \u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"grad_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"grad_b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6233\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6234\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6235\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6236\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6237\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6238\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6239\u001b[0m       return mat_mul_eager_fallback(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
